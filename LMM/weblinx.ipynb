{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install all dependencies\n",
    "# %pip install weblinx[all]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import weblinx as wl\n",
    "\n",
    "\n",
    "wl_dir = Path(\"/ai_dev/cache/hub/datasets--McGill-NLP--WebLINX-full/snapshots/9ac27363e3e340a06fb9df7785a6657be48207a7\")\n",
    "base_dir = wl_dir / \"demonstrations\"\n",
    "# split_path = wl_dir / \"splits.json\"\n",
    "\n",
    "# Load the name of the demonstrations in the training split\n",
    "#demo_names = wl.utils.load_demo_names_in_split(split_path, split='train')\n",
    "# You can use: train, valid, test_iid, test_vis, test_cat, test_geo, test_web\n",
    "# Or you can specify the demo_names yourself, such as the ones we just fetched\n",
    "demo_names = ['aaabtsd', 'aajfwoq', 'aovxytv']  # 3 random demo from valid\n",
    "\n",
    "# Load the demonstrations\n",
    "demos = [wl.Demonstration(name, base_dir=base_dir) for name in demo_names]\n",
    "\n",
    "# Select a demo to work with\n",
    "demo = demos[0]\n",
    "\n",
    "# Load the Replay object, which contains the turns of the demonstration\n",
    "replay = wl.Replay.from_demonstration(demo)\n",
    "\n",
    "# Filter the turns to keep only the ones that are relevant for the task\n",
    "turns = replay.filter_by_intents(\n",
    "    \"click\", \"textInput\", \"load\", \"say\", \"submit\"\n",
    ")\n",
    "\n",
    "# Only keep the turns that have a good screenshot (i.e., the screenshot is not empty)\n",
    "turns = wl.filter_turns(\n",
    "    turns, lambda t: t.has_screenshot() and t.get_screenshot_status() == \"good\"\n",
    ")\n",
    "\n",
    "# Remove chat turns where the speaker is not the navigator (e.g. if you want to train a model to predict the next action)\n",
    "turns = wl.filter_turns(\n",
    "    turns,\n",
    "    lambda turn: not (\n",
    "        turn.type == \"chat\" and turn.get(\"speaker\") != \"navigator\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turns = replay.filter_turns(lambda x: True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(replay.data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in replay.data_dict:\n",
    "    # print(element.keys())\n",
    "    e_type = element[\"type\"]\n",
    "    print(e_type)\n",
    "    if e_type == \"chat\":\n",
    "        print(element[\"speaker\"])\n",
    "        print(element[\"utterance\"])\n",
    "    elif e_type == \"browser\":\n",
    "        print(element[\"state\"].keys())\n",
    "        print(element[\"action\"].keys())\n",
    "        intent = element[\"action\"][\"intent\"]\n",
    "        arguments = element[\"action\"][\"arguments\"]\n",
    "        print(intent)\n",
    "        print(arguments.keys())\n",
    "        print(arguments[\"properties\"])\n",
    "    else:\n",
    "        print(\"UNKOWN ELEMENT TYPE\")\n",
    "    print(\"#\" * 80)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turns = replay.filter_if_screenshot()\n",
    "turns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for turn in turns:\n",
    "    print(turn.intent)\n",
    "    print(turn.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = turns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: We can even get the path to the screenshot and open with Pillow\n",
    "# Install Pillow with: pip install Pillow\n",
    "from PIL import Image\n",
    "Image.open(turns[0].get_screenshot_path())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "turn.get_screenshot_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "# Load the validation split\n",
    "valid = load_dataset(\"McGill-NLP/weblinx\", split=\"validation\")\n",
    "\n",
    "# Download the input templates and use the LLaMA one\n",
    "snapshot_download(\n",
    "    \"McGill-NLP/WebLINX\", repo_type=\"dataset\", allow_patterns=\"templates/*\", local_dir=\".\"\n",
    ")\n",
    "with open('templates/llama.txt') as f:\n",
    "    template = f.read()\n",
    "\n",
    "# To get the input text, simply pass a turn from the valid split to the template\n",
    "turn = valid[0]\n",
    "turn_text = template.format(**turn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
