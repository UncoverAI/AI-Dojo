{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "from model import LlavaNext, ModelConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ollama.pull(\"nomic-embed-text\")\n",
    "ollama.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama.pull(\"nomic-embed-text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "from unstructured.chunking.title import chunk_by_title\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "\n",
    "\n",
    "#  preprocess pdfs inside pdfs directory (whatever PDFs you like)\n",
    "def preprocess_pdfs(directory):\n",
    "  elements = []\n",
    "  for root, _, files in os.walk(directory):\n",
    "    for file in files:\n",
    "        if file.endswith(\".pdf\"):\n",
    "            filename = os.path.join(root,file)\n",
    "            print(filename)\n",
    "            elems = partition_pdf(filename)\n",
    "            print(elems)\n",
    "            elements.extend(elems)\n",
    "  return elements\n",
    "\n",
    "\n",
    "pdf_elements = preprocess_pdfs(\"/ai_dev/AI-Dojo/LMM/pdfs\")\n",
    "\n",
    "\n",
    "# chunking\n",
    "chunked_elements = chunk_by_title(pdf_elements)\n",
    "\n",
    "documents = []\n",
    "for element in chunked_elements:\n",
    "    metadata = element.metadata.to_dict()\n",
    "    documents.append(Document(page_content=element.text,\n",
    "                              metadata=metadata))\n",
    "\n",
    "print(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# db = FAISS.from_documents(documents, OllamaEmbeddings(model=\"nomic-embed-text\",show_progress=True))\n",
    "# retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up the local model:\n",
    "# model_config_json = {\n",
    "#     \"bnb_config\": {\"load_in_4bit\":True, \"bnb_4bit_quant_type\":\"nf4\", \"bnb_4bit_compute_dtype\":\"bfloat16\"},\n",
    "#     \"troch_dtype\":\"bfloat16\",\n",
    "#     \"max_new_tokens\":512\n",
    "# }\n",
    "# model = LlavaNext(ModelConfig(**model_config_json))\n",
    "# model.load_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
