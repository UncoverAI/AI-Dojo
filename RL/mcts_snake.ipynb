{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install gym\n",
    "%pip install numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A game of Snake\n",
    "\n",
    "Playing snake in a command line friendly format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from gym import Env, spaces\n",
    "import numpy as np\n",
    "import random\n",
    "from IPython.display import clear_output\n",
    "\n",
    "class  SnakeEnv(Env):\n",
    "    APPLE = \"A\"\n",
    "    HEAD = \"H\"\n",
    "    BODY = \"S\"\n",
    "    EMPTY = \"O\"\n",
    "    \n",
    "    UP = 'UP'\n",
    "    DOWN = 'DOWN'\n",
    "    RIGHT = 'RIGHT'\n",
    "    LEFT = 'LEFT'\n",
    "    \n",
    "    def __init__(self, tiles:int):\n",
    "        super(SnakeEnv, self).__init__()\n",
    "        self.TILES = tiles\n",
    "\n",
    "        self.actions = [SnakeEnv.UP, SnakeEnv.DOWN, SnakeEnv.LEFT, SnakeEnv.RIGHT]\n",
    "        self.action_space = spaces.Discrete(len(self.actions))\n",
    "        self.observation_space = spaces.Discrete(self.TILES * self.TILES)\n",
    "        \n",
    "        # Inititialze game\n",
    "        self.reset()\n",
    "        \n",
    "    def reset(self):\n",
    "        # Initialize empty grid\n",
    "        self.grid = np.array([[SnakeEnv.EMPTY for x in range(self.TILES)] for y in range(self.TILES)])\n",
    "        \n",
    "        # Add snake head to the grid at random position\n",
    "        start_y = random.randint(0 , self.TILES - 1)\n",
    "        start_x = random.randint(0 , self.TILES - 1)\n",
    "        self.grid[start_y][start_x] = SnakeEnv.HEAD\n",
    "        self.snake = np.array([[start_y, start_x]])\n",
    "        \n",
    "        # Add apple at random position\n",
    "        apple_y, apple_x = self.__generate_apple()\n",
    "        self.grid[apple_y][apple_x] = SnakeEnv.APPLE\n",
    "        self.apple = (apple_y, apple_x)\n",
    "        \n",
    "        # Initialize game variables & last_action memory\n",
    "        self.score = 0\n",
    "        self.terminal = False\n",
    "        self.last_action = None\n",
    "        \n",
    "        return self.grid\n",
    "        \n",
    "    def step(self, action):\n",
    "        # Move the snake\n",
    "        self.__move(direction=action)\n",
    "        \n",
    "        observation = self.grid\n",
    "        done = self.terminal\n",
    "        self.score = len(self.snake)\n",
    "        score = self.score\n",
    "        info = {\"direction\": action}\n",
    "        \n",
    "        return observation, score, done, info\n",
    "    \n",
    "    def get_copy(self):\n",
    "        # Returns a full copy of the game\n",
    "        instance = SnakeEnv(self.TILES)\n",
    "        instance.reset()\n",
    "        instance.grid = deepcopy(self.grid)\n",
    "        instance.snake = deepcopy(self.snake)\n",
    "        instance.apple = self.apple\n",
    "        instance.score = self.score\n",
    "        instance.terminal = self.terminal\n",
    "        instance.last_action = self.last_action\n",
    "        return instance\n",
    "\n",
    "    def __generate_apple(self):\n",
    "        all_grid_positions = {(y,x) for x in range(0, self.TILES) for y in  range(0, self.TILES)}\n",
    "        allowed_grid_positions = list(all_grid_positions - set([tuple(e) for e in self.snake]))\n",
    "        if allowed_grid_positions:\n",
    "            return random.choice(allowed_grid_positions)\n",
    "        else:\n",
    "            # In case the board is full of snake the game will end anyway\n",
    "            return random.choice(list(all_grid_positions))\n",
    "        \n",
    "        \n",
    "    def __move(self, direction):\n",
    "        head_y, head_x = self.snake[-1]\n",
    "        match direction:\n",
    "            case SnakeEnv.UP:\n",
    "                new_head = (head_y -1, head_x)\n",
    "\n",
    "            case SnakeEnv.DOWN:\n",
    "                new_head = (head_y + 1, head_x)\n",
    "\n",
    "            case SnakeEnv.RIGHT:\n",
    "                new_head = (head_y, head_x + 1)\n",
    "\n",
    "            case SnakeEnv.LEFT:\n",
    "                new_head = (head_y, head_x - 1)\n",
    "                \n",
    "\n",
    "        if self.__did_wall_crash(new_head):\n",
    "            self.terminal = True\n",
    "            return\n",
    "        \n",
    "        if self.__did_self_crash(new_head):\n",
    "            self.terminal = True\n",
    "            return\n",
    "        \n",
    "        self.snake = np.append(self.snake, [new_head], axis=0)\n",
    "        self.grid[head_y][head_x] = SnakeEnv.BODY\n",
    "        head_y, head_x = self.snake[-1]\n",
    "        self.grid[head_y][head_x] = SnakeEnv.HEAD\n",
    "        \n",
    "        if self.__did_eat():\n",
    "            apple_y, apple_x = self.__generate_apple()\n",
    "            self.grid[apple_y][apple_x] = SnakeEnv.APPLE\n",
    "            self.apple = (apple_y, apple_x)   \n",
    "        else:\n",
    "            tail_y, tail_x = self.snake[0]\n",
    "            self.snake = self.snake[1:]\n",
    "            self.grid[tail_y][tail_x] = SnakeEnv.EMPTY\n",
    "        \n",
    "        self.last_action = direction\n",
    "    \n",
    "    def __did_eat(self):\n",
    "        eaten = False\n",
    "        head_y, head_x = self.snake[-1]\n",
    "        apple_y, apple_x = self.apple\n",
    "        if (apple_y == head_y) & (apple_x == head_x):\n",
    "            eaten = True\n",
    "        return eaten\n",
    "    \n",
    "    def __did_wall_crash(self, new_head):\n",
    "        head_y, head_x = new_head\n",
    "        if head_y >= self.TILES:\n",
    "            return True\n",
    "        if head_y < 0:\n",
    "            return True\n",
    "        if head_x >= self.TILES:\n",
    "            return True\n",
    "        if head_x < 0:\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def __did_self_crash(self, new_head):\n",
    "        head_y, head_x = new_head\n",
    "        for body_y, body_x in self.snake:\n",
    "            if (body_y == head_y) & (body_x == head_x):\n",
    "                return True\n",
    "        return False\n",
    "        \n",
    "    def render(self, clear:bool = True):\n",
    "        if clear:\n",
    "            clear_output(wait=True)\n",
    "        grid = \"\"\n",
    "        for x in range(self.TILES):\n",
    "            for y in range(self.TILES):\n",
    "                grid += str(self.grid[x][y]) + \" \"\n",
    "            grid += \"\\n\"\n",
    "        print(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O O O O O \n",
      "O O O O O \n",
      "O O O O O \n",
      "A O O O O \n",
      "O H O O O \n",
      "\n",
      "DOWN\n"
     ]
    }
   ],
   "source": [
    "# Testing it out\n",
    "\n",
    "import time\n",
    "\n",
    "game = SnakeEnv(5)\n",
    "game.render()\n",
    "while not game.terminal:\n",
    "    action = random.choice(game.actions)\n",
    "    game.step(action)\n",
    "    game.render()\n",
    "    print(action)\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Monte Carlo Tree Search (MCTS) algorithm\n",
    "\n",
    "Monte Carlo Tree Search (MCTS) is a search algorithm used in decision-making and planning.The search tree consits of nodes (snapshot of the current state of the environment) and edges (actions taken to get from one state/node to the next another).\n",
    "\n",
    "MCTS consits of 4 phases:\n",
    "\n",
    "1. **Selection**: Starting from the root node, MCTS traveses through the search tree selecting the best child of a node until it arrives at a leaf node.\n",
    "\n",
    "2. **Expansion**: Once a leaf node (an unexplored or not fully expanded node) is reached, MCTS expands it by adding a child node representing possible actions or moves.\n",
    "\n",
    "3. **Simulation**: To assess an inital value, MCTS performs simulations from the newly expanded node by randomly selecting actions until a terminal state is reached.\n",
    "\n",
    "4. **Backpropagation**: The result of the simulation is backpropagated up the tree to update the statistics of the nodes in the path from the expanded node to the root.\n",
    "\n",
    "**Making a decision**: Steps 1 to 4 are repeated for a specified number of iterations or until a time limit is reached.\n",
    "Then MCTS decides on the best move by selecting the action leading to the child node with the highest estimated value.\n",
    "\n",
    "The key formula of MCTS is the Upper Confidence Bound (UCB) which is used to decide which child to take during the **Selection** phase.\n",
    "Here's the formula and its components:\n",
    "\n",
    "**Upper Confidence Bound (UCB) Formula:**\n",
    "   - The UCB score for a child node `i` of a parent node `j` is calculated as follows:\n",
    "\n",
    "     ```\n",
    "     UCB(i, j) = Value(i) + C * sqrt(ln(Visits(j)) / Visits(i))\n",
    "     ```\n",
    "\n",
    "   - `Value(i)`: The estimated value of node `i`, typically the average of simulation results.\n",
    "   - `Visits(i)`: The number of times node `i` has been visited.\n",
    "   - `Visits(j)`: The number of times the parent node `j` has been visited.\n",
    "   - `C`: A constant\n",
    "\n",
    "## Tasks:\n",
    "- What does C do?\n",
    "- Now with the formula and the algorithm, walk us through how this will lead to good decisions?\n",
    "- Implement the algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution:\n",
    "\n",
    "- C is used to control the exploration / exploitation tradeoff. The higher C, the more the algorithm will explore instead of continously choosing the highest value node.\n",
    "- During selection current best option (according to UCB) is selected and expanded. The new node receives a value by simulating random actions until a terminal state (assesing the potential of the state). This result is backpropagatged to the current state. Therefore with each iteration the algorithm learns more about the expected values of each action that can be taken from the current state. Given that the number of iterations is choosen high enough, good decisions can be taken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement the Monte Carlo Tree Search algorithm\n",
    "from __future__ import annotations\n",
    "import math\n",
    "\n",
    "class Node():\n",
    "    def __init__(self, state: SnakeEnv, parent: Node):\n",
    "        self.state = state\n",
    "        self.is_terminal = state.terminal\n",
    "        self.parent = parent\n",
    "        self.depth = 0 if parent is None else parent.depth + 1\n",
    "        \n",
    "        self.num_visits = 0\n",
    "        self.value = 0\n",
    "        self.children = {}\n",
    "        self.ucb = float(\"-inf\")\n",
    "\n",
    "class MCTS():\n",
    "    def __init__(self, iterations:int = 1000, exploration_constant:float = math.sqrt(2), discount:float = 0.995, step_cost:float = 0.1):        \n",
    "        self.iterations = iterations\n",
    "        self.C = exploration_constant\n",
    "        \n",
    "        # Bonus: it is good practice to add a discount to diminish value of actions further out in the future\n",
    "        self.discount = discount\n",
    "        # Bonus: adding step cost will ensure that the algorithm does not prefer driving around surviving over risking to eat\n",
    "        self.step_cost = step_cost\n",
    "\n",
    "    def find_best_action(self, current_state: SnakeEnv) -> str:\n",
    "        # Initialize root with current state\n",
    "        root = Node(current_state, None)\n",
    "        \n",
    "        for _ in range(self.iterations):\n",
    "            # Execute 4 steps of one iteration to update the tree\n",
    "            selected_node = self.__selection(root)\n",
    "            added_node = self.__expand(selected_node)\n",
    "            reward = self.__simulation(added_node)\n",
    "            self.__backpropogation(added_node, reward)\n",
    "\n",
    "        # After iteration budget is used, select best action from root node\n",
    "        action = max([(action, node.value) for action, node in root.children.items()],key=lambda x:x[1])[0]\n",
    "        return action\n",
    "        \n",
    "\n",
    "    def __selection(self, node: Node) -> Node:\n",
    "        search_node = node\n",
    "        \n",
    "        is_expandable = len(search_node.children) < len(search_node.state.actions)\n",
    "        # if the selected node can be expanded we stop the search\n",
    "        while not (search_node.is_terminal or is_expandable):\n",
    "            best_ucb = float(\"-inf\")\n",
    "            # track multiple nodes in case of equal UCB values\n",
    "            best_nodes = []\n",
    "            for _, child in search_node.children.items():\n",
    "                # calculate UCB for each child node\n",
    "                child.ucb = child.value / child.num_visits + self.C * math.sqrt(2 * math.log(search_node.num_visits) / child.num_visits)\n",
    "                \n",
    "                if child.ucb > best_ucb:\n",
    "                    best_ucb = child.ucb\n",
    "                    best_nodes = [child]\n",
    "                elif child.ucb == best_ucb:\n",
    "                    best_nodes.append(child)\n",
    "            \n",
    "            # in case of multiple best nodes, randomly choose one\n",
    "            search_node = random.choice(best_nodes)\n",
    "            # check if node is expandable (has unexplored options)\n",
    "            is_expandable = len(search_node.children) < len(search_node.state.actions)\n",
    "        return search_node\n",
    "\n",
    "    def __expand(self, node: Node) ->  Node:\n",
    "        # terminal nodes can not be expanded\n",
    "        if node.is_terminal:\n",
    "            return node\n",
    "        # randomly choose an unexplored action to expand the tree\n",
    "        action = random.choice([a for a in node.state.actions if not a in node.children.keys()])\n",
    "        # create new node and add to the tree\n",
    "        state_copy = node.state.get_copy()\n",
    "        state_copy.step(action)\n",
    "        new_node = Node(state_copy, node)\n",
    "        node.children[action] = new_node\n",
    "        \n",
    "        return new_node\n",
    "            \n",
    "    def __simulation(self, node: Node) -> float:\n",
    "        # if state is terminal no new reward to backpropagate\n",
    "        if node.is_terminal:\n",
    "            return 0\n",
    "        else:\n",
    "            # copy environment to run simulations\n",
    "            state = node.state.get_copy()\n",
    "            reward = state.score\n",
    "            steps = 0\n",
    "\n",
    "            while not state.terminal:\n",
    "                # Bonus: required to remember previous score to see if action led to an improvement\n",
    "                old_score = state.score\n",
    "                \n",
    "                # randomly take an action\n",
    "                action = random.choice(state.actions)\n",
    "                state.step(action)\n",
    "                \n",
    "                # Bonus: punish reward for taking action to avoid pure survival over improving score\n",
    "                step_reward = state.score - old_score - self.step_cost\n",
    "                # Bonus: Discount rewards that our further out in the future\n",
    "                reward += step_reward * (self.discount ** steps)\n",
    "                \n",
    "                # Simple solution (without bonus):\n",
    "                # reward = state.score\n",
    "                \n",
    "                steps += 1\n",
    "\n",
    "            return reward\n",
    "\n",
    "    def __backpropogation(self, node: Node, reward: float) -> None:\n",
    "        # backpropagate from node to root and update visits and value of node\n",
    "        while node is not None:\n",
    "            node.num_visits += 1\n",
    "            node.value += reward\n",
    "            node = node.parent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the algorithm\n",
    "\n",
    "With the set parameters it will be able to mostly play until no space for improvement is left.  \n",
    "If the bonus was done, larger environemnts will work with larger iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S S S S S \n",
      "S S S S S \n",
      "S S S S S \n",
      "S S S H S \n",
      "S S S A O \n",
      "\n",
      "Final score: 23\n"
     ]
    }
   ],
   "source": [
    "game = SnakeEnv(5)\n",
    "searcher = MCTS(iterations=700, exploration_constant=math.sqrt(2), discount=0.995, step_cost=0.1)\n",
    "i = 0\n",
    "\n",
    "print(\"Game reset\")\n",
    "game.reset()\n",
    "initial_state = game.grid\n",
    "action_history = []\n",
    "while not game.terminal:\n",
    "    action = searcher.find_best_action(current_state=game.get_copy())\n",
    "    action_history.append(action)\n",
    "    game.step(action)\n",
    "    game.render()\n",
    "    if game.score == (game.TILES ** 2) - 2:\n",
    "        break\n",
    "time.sleep(1)\n",
    "print(f\"Final score: {game.score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('ai')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bb42a825cb137f8f6f87683b7076f5a8f01f23bcffe8bfce7003eb95672922a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
